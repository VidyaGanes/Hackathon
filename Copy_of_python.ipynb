{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OEoeosRTv-5",
        "outputId": "ea273c02-b236-4b6a-877f-1f42f70dce28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/164.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m122.9/164.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/718.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d10c38a5c91f"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('gemini')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def load_image(path):\n",
        "    \"\"\"Loads an image from the specified path using Pillow.\n",
        "\n",
        "    Args:\n",
        "        path: The path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        The loaded image object, or None if loading fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {path} - {e}\")\n",
        "        return None\n",
        "\n",
        "def classify_image(img):\n",
        "    \"\"\"Classifies the image using a pre-trained MobileNetV2 model.\n",
        "\n",
        "    Args:\n",
        "        img: The image object.\n",
        "\n",
        "    Returns:\n",
        "        The top predicted category.\n",
        "    \"\"\"\n",
        "    model = MobileNetV2(weights='imagenet')\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    predictions = model.predict(img_array)\n",
        "    decoded_predictions = decode_predictions(predictions, top=1)[0][0]\n",
        "    return decoded_predictions[1]  # Return the category name\n",
        "\n",
        "def should_filter_category(category, filter_categories):\n",
        "    \"\"\"Determines if the category should be filtered out.\n",
        "\n",
        "    Args:\n",
        "        category: The category name.\n",
        "        filter_categories: A list of categories to filter out.\n",
        "\n",
        "    Returns:\n",
        "        True if the category should be filtered out, False otherwise.\n",
        "    \"\"\"\n",
        "    return category in filter_categories\n",
        "\n",
        "# Load the image\n",
        "image_path = \"i1.webp\"\n",
        "image_data = load_image(image_path)\n",
        "\n",
        "# Define categories to filter out\n",
        "filter_categories = [\n",
        "    \"cellular telephone\", \"laptop\", \"notebook\", \"monitor\", \"television\",\n",
        "    \"desktop computer\", \"sunglass\", \"handbag\", \"wallet\", \"shoe\", \"refrigerator\",\n",
        "    \"washing machine\", \"microwave\", \"electric toothbrush\", \"hair dryer\",\n",
        "    \"shaver\", \"toy\", \"chair\", \"desk\", \"can\", \"snack\"\n",
        "]\n",
        "\n",
        "# Classify the image\n",
        "if image_data:\n",
        "    category = classify_image(image_data)\n",
        "    print(f\"Detected category: {category}\")\n",
        "\n",
        "    if should_filter_category(category, filter_categories):\n",
        "        print(f\"Image belongs to the filtered category: {category}. Skipping generative model processing.\")\n",
        "    else:\n",
        "        # Create the generative model object\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
        "\n",
        "        # Craft the prompt describing the image\n",
        "        prompt = f\"Analyze the image and describe the most prominent object in it. Include details like brand, design elements, and any text visible on the product.\"\n",
        "\n",
        "        # Generate content based on the prompt and image\n",
        "        response = model.generate_content([prompt, image_data])\n",
        "\n",
        "        # Process the response\n",
        "        for chunk in response:\n",
        "            print(chunk.text)\n"
      ],
      "metadata": {
        "id": "2ohiTOpY_Nll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "17591b4e-214d-4c46-dfce-6eac9c115775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 995ms/step\n",
            "Detected category: cellular_telephone\n",
            "The image showcases a realme GT6T smartphone. The brand name \"realme\" is prominently displayed in lowercase letters at the top of the screen. Just below it, \"GT6T\" is written in a larger, bolder font, clearly identifying the model of the phone. \n",
            "\n",
            "The design features a minimalist aesthetic with a black and white abstract background on the phone's display. The image focuses solely on the device itself, without any distracting background or accessories. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zQyBml0lUh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}